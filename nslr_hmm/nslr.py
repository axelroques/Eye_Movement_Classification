
# Copyleft 2017 Jami Pekkanen <jami.pekkanen@gmail.com>.
# Released under AGPL-3.0, see LICENSE.

# Python implementation of the dynamic programming
# algorithm of NSLR for finding the segmentation.

import numpy as np
import scipy.interpolate

#####################
# NSLR Segmentation #
#####################


class Hypothesis:
    """
    Data structure for the segmentation hypothesis
    """

    def __init__(self, D, j, parent, lik, b):
        # Initialize parent-dependent variables
        self.j = j
        self.parent = parent
        self.lik = lik
        self.b = b
        # Initialize accumulators to zero
        self.a = None
        self.n = 0
        self.t = 0.0
        self.St = 0.0
        self.Stt = 0.0
        self.S = 0
        zeros = np.zeros
        self.Sx = zeros(D)
        self.Sxx = zeros(D)
        self.Stx = zeros(D)


def nslr_segments(ts, xs, noise_stds, split_lik):
    ts = ts.reshape(-1, 1)
    D = len(noise_stds)  # Number of dimensions in the dependent variable
    # Initialize the hypothesis set with a "root" hypothesis
    hypotheses = [Hypothesis(D, j=0, parent=None, lik=0.0, b=None)]
    prev_t = ts[0]
    zeros = np.zeros
    log = np.log
    sqrt = np.sqrt
    pi = np.pi
    for i, (t, x) in enumerate(zip(ts, xs)):  # Iterate over all samples
        dt = t - prev_t
        prev_t = t
        for h in hypotheses:
            # Update the accumulator variables
            h.n += 1
            h.t += dt
            h.St += h.t
            h.Stt += h.t**2
            h.Sx += x
            h.Sxx += x**2
            h.Stx += h.t*x

            if h.parent is None:  # Calculate the intercept for the root hypothesis
                if (h.St**2 - h.n*h.Stt) > 0:
                    h.b = (h.St*h.Stx - h.Stt*h.Sx)/(h.St**2 - h.n*h.Stt)
                else:
                    h.b = h.Sx/h.n

            # Calculate the slope and the residual sums of squares
            if h.Stt > 0.0:
                h.a = (h.Stx - h.b*h.St)/h.Stt
                S = h.a**2*h.Stt + 2*h.a*h.b*h.St - 2*h.a * \
                    h.Stx + h.n*h.b**2 - 2*h.b*h.Sx + h.Sxx
            else:
                S = zeros(D)

            # Update the hypothesis' fitness function
            h.lik += sum(log(1/(sqrt(2*pi)*noise_stds))) + \
                sum((h.S - S)/(2*noise_stds**2))
            h.S = S

        if i == 0:
            continue  # First hypothesis needs at least two samples

        # Get the current most likely hypothesis
        winner = max(hypotheses, key=lambda h: h.lik)
        # Create a new hypothesis starting from the winner's endpoint.
        winner_end = winner.t*winner.a + winner.b
        new_lik = winner.lik + split_lik(dt)  # Add the split likelihood
        new_h = Hypothesis(D, j=i, parent=winner, lik=new_lik, b=winner_end)

        # Prune hypotheses that have lower fitness than the newly formed hypothesis
        hypotheses = [h for h in hypotheses if h.lik > new_lik or h is winner]
        hypotheses.append(new_h)

    # Find the split points J
    h = max(hypotheses, key=lambda h: h.lik)
    splits = [len(ts)]
    while h is not None:
        splits.append(h.j)
        h = h.parent
    return splits[::-1]


#######################
# NSLR Reconstruction #
#######################


def segment_coefficients(ts, xs, J):
    """"
    Produces the matrix coefficients for solving the least 
    squares continuous segmented regression
    """
    ts = ts.reshape(-1, 1)
    Smw0 = 0.0
    Smw0 = 0.0
    Sxw0 = 0.0
    Sww0 = 0.0
    Smm0 = 0.0
    for k in range(len(J) - 1):
        span = slice(J[k], J[k+1])
        t = ts[span]
        x = xs[span]
        dur = (t[-1] - t[0])
        if dur == 0:
            dur = 1.0
        w = (t - t[0])/dur
        m = 1 - w

        Smw1 = (m*w).sum()
        Smm1 = (m*m).sum()
        Sxm1 = (x*m).sum(axis=0)

        p0 = Smw0
        p1 = Smm1 + Sww0
        p2 = Smw1
        y = Sxm1 + Sxw0
        yield p0, p1, p2, y

        Smw0 = Smw1
        Smm0 = Smm1
        Sxm0 = Sxm1
        Sww0 = (w*w).sum()
        Sxw0 = (x*w).sum(axis=0)
    p0 = Smw0
    p1 = 0.0 + Sww0
    p2 = 0.0
    y = 0.0 + Sxw0
    yield p0, p1, p2, y


def segmented_linear_fit(ts, xs, J):
    """
    Uses the tridiagonal matrix algorithm to solve the
    system generated by segment_coefficients. Returns
    the endpoints of the linear segments at times ts[sis]
    """
    bgs = [(0.0, 0.0)]
    for p0, p1, p2, y in segment_coefficients(ts, xs, J):
        b, g = bgs[-1]
        denom = p0*g + p1
        bgs.append(((y - p0*b)/denom, -p2/denom))

    endpoint = 0.0
    endpoints = []
    for b, g in reversed(bgs[1:]):
        endpoint = g*endpoint + b
        endpoints.append(endpoint)
    return endpoints[::-1]


class Segment(object):
    def __init__(self, i, t, x):
        self.i = i
        self.t = t
        self.x = x


class Segmentation(object):
    def __init__(self, t, x, idx):
        self.t = t
        self.x = x
        self.segments = []
        for i in range(len(t)-1):
            s = Segment(
                (idx[i], idx[i+1]),
                (t[i], t[i+1]),
                (x[i], x[i+1]))
            self.segments.append(s)
        self.interp = scipy.interpolate.interp1d(
            self.t, self.x, fill_value='extrapolate', axis=0)

    def __call__(self, nt):
        return self.interp(nt)


def nslr(ts, xs, noise_stds, split_likelihood):
    """
    Runs the NSLR process. 
    Returns times at segment endpoints, estimated dependent variable 
    values at endpoints and the segment endpoint indices.
    """
    J = nslr_segments(ts, xs, noise_stds, split_likelihood)
    endpoints = segmented_linear_fit(ts, xs, J)
    tidx = J[::]
    tidx[-1] -= 1
    return Segmentation(ts[tidx], endpoints, J)


def gaze_split(noise_std,
               saccade_amplitude=3.0,
               slow_phase_duration=0.3,
               slow_phase_speed=5.0):
    log = np.log
    exp = np.exp
    logit_pinc = (
        0.5*(1.0/noise_std) +
        0.5*log(saccade_amplitude*2) +
        -1.0*log(slow_phase_duration*2) +
        0.1*log(slow_phase_speed*2) +
        -3.0)

    def lik(dt):
        lp = logit_pinc + -1.0*log(1/dt)
        return log(1/(1 + exp(-lp)))
    return lik


def fit_gaze(ts, xs, structural_error=0.1,
             optimize_noise=True,
             split_likelihood=gaze_split):
    std = np.std
    mean = np.mean
    structural_error = np.ones(xs[0].shape)*structural_error

    if not optimize_noise:
        return nslr(ts, xs, structural_error, split_likelihood(mean(structural_error)))

    nl = std(xs, axis=0)
    seen = set([tuple(nl)])
    while True:
        nl += structural_error
        fit = nslr(ts, xs, nl, gaze_split(mean(nl)))
        error = fit(ts) - xs
        nl = std(error, axis=0)
        if tuple(nl) in seen:
            return fit
        seen.add(tuple(nl))
